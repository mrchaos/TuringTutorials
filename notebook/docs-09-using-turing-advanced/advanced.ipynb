{
  "cells": [
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Distributions, Turing, Random, Bijectors"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Usage\n\n## How to Define a Customized Distribution\n\n`Turing.jl` supports the use of distributions from the Distributions.jl package. By extension, it also supports the use of customized distributions by defining them as subtypes of `Distribution` type of the Distributions.jl package, as well as corresponding functions.\n\nBelow shows a workflow of how to define a customized distribution, using our own implementation of a simple `Uniform` distribution as a simple example.\n\n### 1. Define the Distribution Type\n\nFirst, define a type of the distribution, as a subtype of a corresponding distribution type in the Distributions.jl package."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "struct CustomUniform <: ContinuousUnivariateDistribution end"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Implement Sampling and Evaluation of the log-pdf\n\nSecond, define `rand` and `logpdf`, which will be used to run the model."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# sample in [0, 1]\nDistributions.rand(rng::AbstractRNG, d::CustomUniform) = rand(rng)\n\n# p(x) = 1 → logp(x) = 0\nDistributions.logpdf(d::CustomUniform, x::Real) = zero(x)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Define Helper Functions\n\nIn most cases, it may be required to define some helper functions.\n\n#### 3.1 Domain Transformation\n\nCertain samplers, such as `HMC`, require the domain of the priors to be unbounded. Therefore, to use our `CustomUniform` as a prior in a model we also need to define how to transform samples from `[0, 1]` to `ℝ`. To do this, we simply need to define the corresponding `Bijector` from `Bijectors.jl`, which is what `Turing.jl` uses internally to deal with constrained distributions.\n\nTo transform from `[0, 1]` to `ℝ` we can use the `Logit` bijector:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "Bijectors.bijector(d::CustomUniform) = Logit(0.0, 1.0)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'd do the exact same thing for `ContinuousMultivariateDistribution` and `ContinuousMatrixDistribution`. For example, `Wishart` defines a distribution over positive-definite matrices and so `bijector` returns a `PDBijector` when called with a `Wishart` distribution as an argument. For discrete distributions, there is no need to define a bijector; the `Identity` bijector is used by default.\n\nAlternatively, for `UnivariateDistribution` we can define the `minimum` and `maximum` of the distribution"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "Distributions.minimum(d::CustomUniform) = 0.0\nDistributions.maximum(d::CustomUniform) = 1.0"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "and `Bijectors.jl` will return a default `Bijector` called `TruncatedBijector` which makes use of `minimum` and `maximum` derive the correct transformation.\n\nInternally, Turing basically does the following when it needs to convert a constrained distribution to an unconstrained distribution, e.g. when sampling using `HMC`:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "dist = Gamma(2,3)\nb = bijector(dist)\ntransformed_dist = transformed(dist, b) # results in distribution with transformed support + correction for logpdf"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "and then we can call `rand` and `logpdf` as usual, where\n\n  - `rand(transformed_dist)` returns a sample in the unconstrained space, and\n  - `logpdf(transformed_dist, y)` returns the log density of the original distribution, but with `y` living in the unconstrained space.\n\nTo read more about Bijectors.jl, check out [the project README](https://github.com/TuringLang/Bijectors.jl).\n\n## Update the accumulated log probability in the model definition\n\nTuring accumulates log probabilities internally in an internal data structure that is accessible through\nthe internal variable `__varinfo__` inside of the model definition (see below for more details about model internals).\nHowever, since users should not have to deal with internal data structures, a macro `Turing.@addlogprob!` is provided\nthat increases the accumulated log probability. For instance, this allows you to\n[include arbitrary terms in the likelihood](https://github.com/TuringLang/Turing.jl/issues/1332)"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Turing\n\nmyloglikelihood(x, μ) = loglikelihood(Normal(μ, 1), x)\n\n@model function demo(x)\n    μ ~ Normal()\n    Turing.@addlogprob! myloglikelihood(x, μ)\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "and to [reject samples](https://github.com/TuringLang/Turing.jl/issues/1328):"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Turing\nusing LinearAlgebra\n\n@model function demo(x)\n    m ~ MvNormal(zero(x), I)\n    if dot(m, x) < 0\n        Turing.@addlogprob! -Inf\n        # Exit the model evaluation early\n        return nothing\n    end\n\n    x ~ MvNormal(m, I)\n    return nothing\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that `@addlogprob!` always increases the accumulated log probability, regardless of the provided\nsampling context. For instance, if you do not want to apply `Turing.@addlogprob!` when evaluating the\nprior of your model but only when computing the log likelihood and the log joint probability, then you\nshould [check the type of the internal variable `__context_`](https://github.com/TuringLang/DynamicPPL.jl/issues/154)\nsuch as"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "if DynamicPPL.leafcontext(__context__) !== Turing.PriorContext()\n    Turing.@addlogprob! myloglikelihood(x, μ)\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Internals\n\nThe `@model` macro accepts a function definition and rewrites it such that call of the function generates a `Model` struct for use by the sampler.\nModels can be constructed by hand without the use of a macro.\nTaking the `gdemo` model as an example, the macro-based definition"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Turing\n\n@model function gdemo(x)\n    # Set priors.\n    s² ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s²))\n\n    # Observe each value of x.\n    @. x ~ Normal(m, sqrt(s²))\nend\n\nmodel = gdemo([1.5, 2.0])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "can be implemented also (a bit less generally) with the macro-free version"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Turing\n\n# Create the model function.\nfunction gdemo(model, varinfo, context, x)\n    # Assume s² has an InverseGamma distribution.\n    s², varinfo = DynamicPPL.tilde_assume!!(\n        context, InverseGamma(2, 3), Turing.@varname(s²), varinfo\n    )\n\n    # Assume m has a Normal distribution.\n    m, varinfo = DynamicPPL.tilde_assume!!(\n        context, Normal(0, sqrt(s²)), Turing.@varname(m), varinfo\n    )\n\n    # Observe each value of x[i] according to a Normal distribution.\n    return DynamicPPL.dot_tilde_observe!!(\n        context, Normal(m, sqrt(s²)), x, Turing.@varname(x), varinfo\n    )\nend\ngdemo(x) = Turing.Model(gdemo, (; x))\n\n# Instantiate a Model object with our data variables.\nmodel = gdemo([1.5, 2.0])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task Copying\n\nTuring [copies](https://github.com/JuliaLang/julia/issues/4085) Julia tasks to\ndeliver efficient inference algorithms, but it also provides alternative slower\nimplementation as a fallback. Task copying is enabled by default. Task copying\nrequires us to use the `TapedTask` facility which is provided by\n[Libtask](https://github.com/TuringLang/Libtask.jl) to create tasks."
      ],
      "metadata": {}
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.9.2"
    },
    "kernelspec": {
      "name": "julia-1.9",
      "display_name": "Julia 1.9.2",
      "language": "julia"
    }
  },
  "nbformat": 4
}
